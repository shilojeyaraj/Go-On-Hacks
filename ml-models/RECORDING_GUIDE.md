# Video Recording Guide for Better Gesture Recognition
## How to Record High-Quality YES Gesture Videos

### üéØ **Goal**
Record clear, distinctive YES (nodding) gestures that are easily distinguishable from NO (shaking) gestures.

---

## ‚úÖ **YES Gesture (Nodding) - What to Do**

### **The Gesture:**
- **Nod your head UP and DOWN** repeatedly
- Move your head in a **vertical motion** (like saying "yes")
- Do **3-5 clear nods** per recording
- Make the movement **deliberate and clear**

### **Key Tips:**
1. **Exaggerate the movement** - bigger is better for training
2. **Keep your face forward** - don't tilt side to side
3. **Nod at a steady pace** - not too fast, not too slow
4. **Full range of motion** - head up, then head down
5. **Multiple angles** - slight variations in starting position help

### **What Makes a GOOD YES Video:**
- ‚úÖ Clear vertical head movement
- ‚úÖ Face stays centered (no side-to-side movement)
- ‚úÖ Good lighting on your face
- ‚úÖ Face clearly visible throughout
- ‚úÖ 3-5 distinct nods
- ‚úÖ Smooth, natural motion

### **What to AVOID:**
- ‚ùå Diagonal movements (mixing up/down with side/side)
- ‚ùå Too subtle movements (model can't detect)
- ‚ùå Moving too fast (blurry)
- ‚ùå Looking away from camera
- ‚ùå Poor lighting or shadows
- ‚ùå Face too close or too far from camera

---

## üìπ **Recording Setup**

### **Camera Position:**
- Place camera at **eye level** or slightly above
- Distance: **2-3 feet** from your face (arm's length)
- Keep your **entire head in frame** with some space above

### **Lighting:**
- **Bright, even lighting** on your face
- Face the light source (window or lamp)
- Avoid backlighting (light behind you)
- No harsh shadows on face

### **Background:**
- Any background is fine
- Neutral/plain backgrounds work best
- Avoid cluttered or busy backgrounds

### **Duration:**
- Each video: **3-8 seconds**
- Perform **3-5 complete nods** per video
- Don't need long videos - quality over quantity!

---

## üé¨ **Recording Process**

### **How Many Videos to Record:**
- **Minimum:** 5-8 videos
- **Recommended:** 10-15 videos
- **Ideal:** 15-20 videos

The more variety you have, the better the model learns!

### **Add Variety (Important!):**
Record multiple sessions with different:
1. **Starting positions:**
   - Start with head neutral
   - Start with head slightly up
   - Start with head slightly tilted

2. **Speed variations:**
   - Slow, deliberate nods
   - Medium pace nods
   - Quick nods

3. **Intensity:**
   - Small nods (subtle)
   - Medium nods (normal)
   - Large nods (exaggerated)

4. **Context:**
   - Different times of day
   - Different lighting conditions
   - Wearing different things (glasses on/off, hat, etc.)
   - Different facial expressions (neutral, smiling)

---

## üì± **Recording Methods**

### **Option 1: Webcam (Easiest)**
```bash
# Windows Camera app
1. Press Windows key
2. Type "Camera"
3. Open Camera app
4. Click video mode
5. Record 5-8 seconds per video
6. Save and repeat
```

### **Option 2: Phone Camera**
1. Use rear camera (better quality)
2. Prop phone on stand or lean against something
3. Use video mode
4. Record each gesture
5. Transfer videos to computer

### **Option 3: Record with Python (Advanced)**
```python
# Quick recording script
python 1_upload_videos.py
# This has recording capability built in
```

---

## üíæ **Saving Your Videos**

### **File Format:**
- ‚úÖ **MP4** (preferred)
- ‚úÖ **MOV** (works great)
- ‚úÖ **AVI** (works)
- ‚úÖ **WEBM** (works)

### **File Location:**
Save ALL your YES gesture videos to:
```
ml-models/videos/yes/
```

### **File Naming:**
- Any name is fine!
- Examples: `yes_001.mp4`, `nod_session1.mov`, `PXL_20251108_160653673.mp4`

---

## üéØ **Example Recording Session**

Here's a sample 15-video recording session:

**Session 1 (5 videos) - Normal speed:**
1. `yes_normal_01.mp4` - Medium nods, neutral face
2. `yes_normal_02.mp4` - Medium nods, slight smile
3. `yes_normal_03.mp4` - Medium nods, different starting position
4. `yes_normal_04.mp4` - Medium nods, glasses on
5. `yes_normal_05.mp4` - Medium nods, different lighting

**Session 2 (5 videos) - Slow & exaggerated:**
6. `yes_slow_01.mp4` - Large, slow nods
7. `yes_slow_02.mp4` - Large, slow nods, different angle
8. `yes_slow_03.mp4` - Large, slow nods, starting high
9. `yes_slow_04.mp4` - Large, slow nods, starting low
10. `yes_slow_05.mp4` - Large, slow nods, enthusiastic

**Session 3 (5 videos) - Quick & subtle:**
11. `yes_quick_01.mp4` - Faster nods
12. `yes_quick_02.mp4` - Faster nods, slight variation
13. `yes_subtle_01.mp4` - Smaller, more subtle nods
14. `yes_subtle_02.mp4` - Smaller nods, different context
15. `yes_final_01.mp4` - Mix of speeds

---

## ‚ú® **Quick Checklist Before Recording**

- [ ] Camera at eye level
- [ ] Good lighting on face
- [ ] Face fully in frame
- [ ] Ready to do 3-5 clear nods
- [ ] Focused on VERTICAL motion only
- [ ] Not mixing with horizontal movement
- [ ] Exaggerating the gesture slightly
- [ ] Will record 10-15 different variations

---

## üöÄ **After Recording**

### **1. Check Your Videos:**
- Play them back to verify they're clear
- Make sure face is visible
- Confirm the gesture is obvious

### **2. Move to Correct Folder:**
- Copy/move all YES videos to: `ml-models/videos/yes/`
- Keep your existing videos too (don't delete)

### **3. Re-train the Model:**
```bash
cd ml-models

# Step 1: Extract features from new videos
python 2_extract_features.py

# Step 2: Train model with new data
python 3_train_model.py

# Step 3: Test it!
python quick_test.py
```

---

## üé≠ **Bonus: Testing Your Videos**

Want to see if your YES gestures are distinct? Compare:

**YES gesture characteristics:**
- Primary motion: **VERTICAL** (up/down)
- Face moves: **Up then Down** repeatedly
- Chin goes: **Up to ceiling, down to chest**

**NO gesture characteristics:**
- Primary motion: **HORIZONTAL** (left/right)
- Face rotates: **Left then Right** repeatedly
- Nose points: **Left wall, then right wall**

If your YES videos look too similar to your NO videos, the model will struggle!

---

## üìä **Expected Results**

After recording 10-15 good YES videos:
- **Before:** 37.5% YES recall (very poor)
- **Target:** 80%+ YES recall (good)
- **Ideal:** 90%+ YES recall (excellent)

---

## ‚ùì **Troubleshooting**

**Q: How do I know if my YES gesture is good?**
A: Play back the video - if YOU can clearly see the up/down nodding motion, it's good!

**Q: Should I look at the camera?**
A: Yes! Keep your eyes forward, looking at the camera.

**Q: Can I record multiple people?**
A: Yes! More people = more variety = better model!

**Q: How long should each video be?**
A: 3-8 seconds is perfect. Long enough for 3-5 nods.

**Q: What if my videos are too large?**
A: That's fine! The script will process them. Phone videos work great.

---

## üéâ **Ready to Record?**

1. Set up your camera with good lighting
2. Record 10-15 YES gesture videos (3-8 seconds each)
3. Save them to `ml-models/videos/yes/`
4. Run training pipeline
5. Test and enjoy your improved model!

**Good luck! Your model will perform much better with more variety in the YES gestures! üöÄ**

